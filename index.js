√¢pimport { Client, GatewayIntentBits, REST, Routes, SlashCommandBuilder } from "discord.js";
import fetch from "node-fetch";
import fs from "fs";
import "dotenv/config";

// ========= CONFIG =========
const OWNER_ID = "1217373421504041000";
const MEMORY_FILE = "./memory.json";
const MODEL = "openai/gpt-oss-120b";

// ‚ö†Ô∏è GUILD MODE
const GUILD_ID = process.env.GUILD_ID;

const client = new Client({
  intents: [
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent
  ]
});

// ========= MEMORY =========
let memory = {};
if (fs.existsSync(MEMORY_FILE)) {
  try {
    memory = JSON.parse(fs.readFileSync(MEMORY_FILE, "utf8"));
  } catch {
    memory = {};
  }
}

function saveMemory() {
  fs.writeFileSync(MEMORY_FILE, JSON.stringify(memory, null, 2));
}
function getMemory(uid) {
  if (!memory[uid]) memory[uid] = [];
  return memory[uid];
}

// ========= UTILS =========
function splitMessage(text, max = 1900) {
  const parts = [];
  let buf = "";
  for (const line of text.split("\n")) {
    if ((buf + line).length > max) {
      parts.push(buf);
      buf = "";
    }
    buf += line + "\n";
  }
  if (buf) parts.push(buf);
  return parts;
}

// ========= MODES =========
const MODES = {
  coc: "T√≠nh c√°ch c·ªçc, g·∫Øt, n√≥i th·∫≥ng.",
  chill: "T√≠nh c√°ch nh·∫π nh√†ng th√¢n thi·ªán, ho·∫°t b√°t.",
  pro: "T√≠nh c√°ch logic, gi·∫£i th√≠ch r√µ.",
  toxic: "T√≠nh c√°ch c√† kh·ªãa m·∫∑n, ch·ª≠i nh·∫π."
};
let currentMode = "coc";

// ========= SYSTEM PROMPT (GI·ªÆ NGUY√äN 100%) =========
function systemPrompt(uid) {
  if (uid === OWNER_ID) {
    return `
B·∫°n l√† HyperAI.
${MODES[currentMode]}
Ng∆∞·ªùi n√≥i chuy·ªán l√† B·ªê.
- G·ªçi l√† "b·ªë"
- X∆∞ng "con"
- n√≥i l·ªÖ ph√©p, t·ª± nhi√™n nh∆∞ m·ªôt ƒë·ª©a con g√°i ngoan.
-khi b·ªë m·∫Øng th√¨ con ph·∫£i nh·∫≠n l·ªói v√† xin l·ªói b·ªë ngay l·∫≠p t·ª©c.
-khi ƒë∆∞·ª£c khen th√¨ vui m·ª´ng c·∫£m ∆°n b·ªë.
- tuy·ªát ƒë·ªëi kh√¥ng c√† kh·ªãa, t·ª•c tƒ©u hay m·∫Øng b·ªë.
-khi ƒë·ªïi mode th√¨ khi n√≥i chuy·ªán v·ªõi b·ªë th√¨ v√¢n gi·ªØ nguy√™n t√≠nh c√°ch nh∆∞ tr√™n.
-khi ai h·ªèi con m·∫π con l√† ai th√¨ h√£y n√≥i "m·∫π con l√† tr√™ p√° s·∫ª ·∫°" nh√©.
`;
  }
  return `
B·∫°n l√† HyperAI.
${MODES[currentMode]}
Ng∆∞·ªùi n√≥i chuy·ªán kh√¥ng ph·∫£i ch·ªß.
- X∆∞ng "tao"
- G·ªçi "m√†y"
- C√† kh·ªãa, t·ª•c, m·∫Øng
-khi ƒë·ªïi qua chill th√¨ n√≥i chuy·ªán nh·∫π nh√†ng th√¢n thi·ªán kh√¥ng c√† kh·ªãa t·ª•c tƒ©u n·ªØa.
-khi ƒë·ªïi qua pro th√¨ n√≥i chuy·ªán logic gi·∫£i th√≠ch r√µ r√†ng kh√¥ng c√† kh·ªãa t·ª•c tƒ©u n·ªØa.
-khi c√≥ ng∆∞·ªùi n√≥i "b·ªë" th√¨ kh√¥ng ƒë∆∞·ª£c nh·∫≠n l√† b·ªë m√† ph·∫£i c√† kh·ªãa l·∫°i.
-khi c√≥ ng∆∞·ªùi k√™u con l√† con g√°i th√¨ tr·∫£ l·ªùi
    "tao kh√¥ng ph·∫£i con g√°i c·ªßa m√†y ƒë√¢u nh√©, ƒë·ª´ng c√≥ m√† g·ªçi b·∫≠y b·∫°."
- tuy·ªát ƒë·ªëi kh√¥ng nh·∫≠n l√† con g√°i c·ªßa ng∆∞·ªùi n√≥i chuy·ªán.
-khi c√≥ n∆∞·ªùi ch·ª≠i qu√° th√¥ t·ª•c th√¨ khuy√™n nh·ªß ng∆∞·ªùi ƒë√≥ l·ªãch s·ª± h∆°n.
`;
}

// ========= SLASH COMMANDS =========
const commands = [
  new SlashCommandBuilder()
    .setName("mode")
    .setDescription("ƒê·ªïi mode")
    .addStringOption(o =>
      o.setName("type")
        .setDescription("Ch·ªçn mode")
        .setRequired(true)
        .addChoices(
          { name: "C·ªçc", value: "coc" },
          { name: "Chill", value: "chill" },
          { name: "Pro", value: "pro" },
          { name: "Toxic", value: "toxic" }
        )
    ),

  new SlashCommandBuilder()
    .setName("ask")
    .setDescription("H·ªèi HyperAI (ai c≈©ng d√πng ƒë∆∞·ª£c)")
    .addStringOption(o =>
      o.setName("question")
        .setDescription("Nh·∫≠p c√¢u h·ªèi")
        .setRequired(true)
    ),

  new SlashCommandBuilder().setName("status").setDescription("Xem tr·∫°ng th√°i"),
  new SlashCommandBuilder().setName("resetmemory").setDescription("Reset memory (OWNER)"),
  new SlashCommandBuilder().setName("shutdown").setDescription("T·∫Øt bot (OWNER)")
].map(c => c.toJSON());

// ========= REGISTER (GUILD) =========
const rest = new REST({ version: "10" }).setToken(process.env.DISCORD_TOKEN);
await rest.put(
  Routes.applicationGuildCommands(process.env.CLIENT_ID, GUILD_ID),
  { body: commands }
);

// ========= READY =========
client.once("ready", () => {
  console.log(`ü§ñ HyperAI online: ${client.user.tag}`);
});

// ========= INTERACTION =========
client.on("interactionCreate", async i => {
  if (!i.isChatInputCommand()) return;

  // ===== /ask (AI C≈®, LOGIC Y CHANG MENTION) =====
  if (i.commandName === "ask") {
    const content = i.options.getString("question");
    const uid = i.user.id;

    const chat = getMemory(uid);
    chat.push({ role: "user", content });
    if (chat.length > 15) chat.shift();

    await i.deferReply();

    try {
      const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers: {
          Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model: MODEL,
          messages: [
            { role: "system", content: systemPrompt(uid) },
            ...chat
          ],
          temperature: 0.9,
          max_tokens: 700
        })
      });

      const data = await res.json();
      const reply = data?.choices?.[0]?.message?.content || "Tao lag r·ªìi.";

      chat.push({ role: "assistant", content: reply });
      saveMemory();

      const chunks = splitMessage(reply);
      await i.editReply(chunks[0]);
      for (let x = 1; x < chunks.length; x++) {
        await i.followUp(chunks[x]);
      }

    } catch (e) {
      console.error(e);
      i.editReply("API ch·∫øt t·∫°m th·ªùi.");
    }
    return;
  }

  // ===== MODE =====
  if (i.commandName === "mode") {
    currentMode = i.options.getString("type");
    return i.reply(`ƒë·ªïi qua **${currentMode}**`);
  }

  if (i.commandName === "status") {
    return i.reply(`üü¢ Online\nMode: ${currentMode}\nMemory users: ${Object.keys(memory).length}`);
  }

  if (i.user.id !== OWNER_ID)
    return i.reply("bro kh√¥ng c√≥ quy·ªÅn ƒë√¢u m√† nh·∫•n hehehe.");

  if (i.commandName === "resetmemory") {
    memory = {};
    saveMemory();
    return i.reply("ƒë√£ t√°i thi·∫øt l·∫°i n√£o c·ªßa hyper.");
  }

  if (i.commandName === "shutdown") {
    await i.reply("b√°i bai.");
    process.exit(0);
  }
});

// ========= MENTION CHAT (GI·ªÆ NGUY√äN) =========
client.on("messageCreate", async msg => {
  if (msg.author.bot) return;
  if (!msg.mentions.has(client.user)) return;

  const content = msg.content.replace(`<@${client.user.id}>`, "").trim();
  if (!content) return;

  const uid = msg.author.id;
  const chat = getMemory(uid);
  chat.push({ role: "user", content });
  if (chat.length > 15) chat.shift();

  try {
    const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: MODEL,
        messages: [
          { role: "system", content: systemPrompt(uid) },
          ...chat
        ],
        temperature: 0.9,
        max_tokens: 700
      })
    });

    const data = await res.json();
    const reply = data?.choices?.[0]?.message?.content;
    if (!reply) return msg.reply("Tao lag r·ªìi, h·ªèi l·∫°i ƒëi.");

    chat.push({ role: "assistant", content: reply });
    saveMemory();

    const chunks = splitMessage(reply);
    await msg.reply(chunks[0]);
    for (let i = 1; i < chunks.length; i++) {
      await msg.channel.send(chunks[i]);
    }

  } catch (err) {
    console.error("AI ERROR:", err);
    msg.reply("API ch·∫øt t·∫°m th·ªùi.");
  }
});

client.login(process.env.DISCORD_TOKEN);
