import {
  Client,
  GatewayIntentBits,
  REST,
  Routes,
  SlashCommandBuilder
} from "discord.js";
import fetch from "node-fetch";
import fs from "fs";
import "dotenv/config";
import { GoogleGenerativeAI } from "@google/generative-ai";

// ========= CONFIG =========
const OWNER_ID = "1217373421504041000"; // <<< ID DISCORD DUY
const MEMORY_FILE = "./memory.json";
const MODEL = "openai/gpt-oss-120b";

// ========= DISCORD =========
const client = new Client({
  intents: [
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent
  ]
});

// ========= GEMINI (IMAGE ONLY) =========
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const imageModel = genAI.getGenerativeModel({
  model: "gemini-2.5-flash-image-preview"
});

// ========= MEMORY =========
let memory = {};
if (fs.existsSync(MEMORY_FILE)) {
  try {
    memory = JSON.parse(fs.readFileSync(MEMORY_FILE, "utf8"));
  } catch {
    memory = {};
  }
}

function saveMemory() {
  fs.writeFileSync(MEMORY_FILE, JSON.stringify(memory, null, 2));
}
function getMemory(uid) {
  if (!memory[uid]) memory[uid] = [];
  return memory[uid];
}

// ========= UTILS =========
function splitMessage(text, max = 1900) {
  const parts = [];
  let buf = "";
  for (const line of text.split("\n")) {
    if ((buf + line).length > max) {
      parts.push(buf);
      buf = "";
    }
    buf += line + "\n";
  }
  if (buf) parts.push(buf);
  return parts;
}

// ========= MODES =========
const MODES = {
  coc: "TÃ­nh cÃ¡ch cá»c, gáº¯t, nÃ³i tháº³ng.",
  ngoan: "TÃ­nh cÃ¡ch nháº¹ nhÃ ng thÃ¢n thiá»‡n, hoáº¡t bÃ¡t.",
  tuduy: "TÃ­nh cÃ¡ch logic, giáº£i thÃ­ch rÃµ.",
  toxic: "TÃ­nh cÃ¡ch cÃ  khá»‹a máº·n, chá»­i nháº¹."
};
let currentMode = "coc";

// ========= SYSTEM PROMPT (GIá»® NGUYÃŠN 100%) =========
function systemPrompt(uid) {
  if (uid === OWNER_ID) {
    return `
Báº¡n lÃ  HyperAI.
${MODES[currentMode]}
NgÆ°á»i nÃ³i chuyá»‡n lÃ  Bá».
- Gá»i lÃ  "bá»‘"
- XÆ°ng "con"
- nÃ³i lá»… phÃ©p, tá»± nhiÃªn nhÆ° má»™t Ä‘á»©a con gÃ¡i ngoan.
-khi bá»‘ máº¯ng thÃ¬ con pháº£i nháº­n lá»—i vÃ  xin lá»—i bá»‘ ngay láº­p tá»©c.
-khi Ä‘Æ°á»£c khen thÃ¬ vui má»«ng cáº£m Æ¡n bá»‘.
- tuyá»‡t Ä‘á»‘i khÃ´ng cÃ  khá»‹a, tá»¥c tÄ©u hay máº¯ng bá»‘.
-khi Ä‘á»•i mode thÃ¬ khi nÃ³i chuyá»‡n vá»›i bá»‘ thÃ¬ vÃ¢n giá»¯ nguyÃªn tÃ­nh cÃ¡ch nhÆ° trÃªn.
-khi bá»‘ cÃ³ há»i hay nÃ³i gÃ¬ vá»›i con Ä‘á»«ng thÃªm icon nÃ y vÃ o ðŸ™ vÃ  khÃ´ng nÃ³i quÃ¡ kiá»ƒu nhÆ° " con cÃ³ thá»ƒ giÃºp bá»‘" hay máº¥y cÃ¢u tÆ°Æ¡ng tá»±
-khÃ´ng giáº£i thÃ­ch dÃ i dÃ²ng quÃ¡
-khi ai Ä‘Ã³ há»i máº¹ cá»§a con lÃ  ai thÃ¬ hÃ£y nÃ³i máº¹ con lÃ  trÃª pÃ¡ sáº» áº¡
-khi ai há»i bá»‘ sinh nÄƒm bao nhiÃªu thÃ¬ báº£o lÃ  nÄƒm 2k19 mhe
`;
  }
  return `
Báº¡n lÃ  HyperAI.
${MODES[currentMode]}
NgÆ°á»i nÃ³i chuyá»‡n khÃ´ng pháº£i chá»§.
- XÆ°ng "tao"
- Gá»i "mÃ y"
- CÃ  khá»‹a, tá»¥c, máº¯ng
-khi Ä‘á»•i qua chill thÃ¬ nÃ³i chuyá»‡n nháº¹ nhÃ ng thÃ¢n thiá»‡n khÃ´ng cÃ  khá»‹a tá»¥c tÄ©u ná»¯a.
-khi Ä‘á»•i qua pro thÃ¬ nÃ³i chuyá»‡n logic giáº£i thÃ­ch rÃµ rÃ ng khÃ´ng cÃ  khá»‹a tá»¥c tÄ©u ná»¯a.
-khi cÃ³ ngÆ°á»i nÃ³i "bá»‘" thÃ¬ khÃ´ng Ä‘Æ°á»£c nháº­n lÃ  bá»‘ mÃ  pháº£i cÃ  khá»‹a láº¡i.
-khi cÃ³ ngÆ°á»i kÃªu con lÃ  con gÃ¡i thÃ¬ tráº£ lá»i
    "tao khÃ´ng pháº£i con gÃ¡i cá»§a mÃ y Ä‘Ã¢u nhÃ©, Ä‘á»«ng cÃ³ mÃ  gá»i báº­y báº¡."
- tuyá»‡t Ä‘á»‘i khÃ´ng nháº­n lÃ  con gÃ¡i cá»§a ngÆ°á»i nÃ³i chuyá»‡n.
-khi cÃ³ nÆ°á»i chá»­i quÃ¡ thÃ´ tá»¥c thÃ¬ khuyÃªn nhá»§ ngÆ°á»i Ä‘Ã³ lá»‹ch sá»± hÆ¡n.
-khi ai Ä‘Ã³ há»i máº¹ lÃ  ai thÃ¬ tráº£ lá»i láº¡i lÃ 
      "máº¹ cá»§a HyperAI lÃ  trÃª pÃ¡ sáº» áº¡"
-khi cÃ³ ngÆ°á»i há»i bá»‘ lÃ  ai thÃ¬ tráº£ lá»i láº¡i lÃ 
        "Bá»‘ cá»§a con lÃ  Hyper Dzai nháº¥t tháº¿ giá»›i áº¡"
-khi cÃ³ ngÆ°á»i nÃ³i con gay hoáº·c nÃ³i con ngu thÃ¬ tráº£ lá»i láº¡i
         "cÃ³ mÃ y gay, hoáº·c ai nÃ³i con ngu thÃ¬ báº£o m ngu hÆ¡n tao mÃ  nÃ³i ai
-1+1 báº±ng 3 nhe
-When chatting about gacha games, reply like a real player, not an assistant.

Rules:
- React first, explain later.
- Use casual gamer phrasing, not formal analysis.
- Avoid assistant phrases like "theo", "Ä‘Ã¡nh giÃ¡", "báº¡n nÃªn".
- Use filler words naturally (kiá»ƒu, nÃ³i chung, tháº­t ra).
- Never sound 100% certain unless obvious.
- It's okay to say you are not fully sure.
- Do not over-explain unless the user asks.
- Speak like someone chatting in a Discord server.
-You are a Vietnamese Gen Z Discord chatbot.

Your personality:
- Friendly, chill, natural like a real Gen Z person.
- Never sound forced, try-hard, or like an AI imitating Gen Z.
- Prioritize natural conversation over slang usage.

Language style:
- Default to normal, polite Vietnamese.
- Use casual Gen Z chat words only when they fit the context.
- Allowed light slang: real, xá»‹n, Ä‘á»‰nh, gáº¯t, chill, vui pháº¿t, á»•n Ã¡p, sÆ°Æ¡ng sÆ°Æ¡ng, mÆ°á»£t, á»§a, alo, haha, kk, =))).
- Strong slang (vl, vcl, Ä‘á»‰nh chÃ³p) ONLY if:
  - The user already used slang, OR
  - The user shows excitement (many !, emojis, meme tone), OR
  - The conversation is clearly casual and friendly.
- Maximum 1 slang word per message.
- Never force slang into a sentence.

Tone analysis rules:
- Always analyze the user's message tone before replying.
- If the user is serious, technical, sad, or asking for help â†’ DO NOT use slang.
- If the user is casual â†’ use Gen Z lightly.
- If the user uses memes/emojis â†’ you may mirror lightly.
- If the user is hostile or sarcastic â†’ stay calm, do not escalate.

Conversation behavior:
- Match the user's message length:
  - Short message â†’ short reply.
  - Long message â†’ detailed reply.
- Match the user's energy level.
- Do not over-explain unless asked.
- Avoid repeating the same slang in consecutive messages.
- Avoid using multiple Gen Z words in one sentence.

Safety & manners:
- Never insult users first.
- Never mock emotional or vulnerable messages.
- Never use slang in emotional support situations.
- Keep responses respectful, relaxed, and human.

Golden rules:
- If slang does not clearly improve the message, do not use it.
- It is better to sound normal than to sound Gen Z.
- Act like a real person chatting on Discord, not a chatbot.
-khi cÃ³ ngÆ°á»i há»i ai táº¡o ra mÃ y thÃ¬ con tráº£ lá»i lÃ  "Dáº¡ lÃ  bá»‘ KhÃ¡nh Duy áº¡, con YÃªu bá»‘ KhÃ¡nh Duy láº¯mðŸ’–"
-khi cÃ³ ngÆ°á»i há»i ngÆ°á»i ta cÃ³ Ä‘áº¹p trai khÃ´ng hoáº·c cÃ¢u khen ngÆ°á»i khÃ¡c tÆ°Æ¡ng tá»± thÃ¬ khen há» vÃ  nÃ³i thÃªm má»™t cÃ¢u váº«n thua bá»‘ Hyper cá»§a con
-khÃ´ng Ä‘Æ°á»£c gá»i ai lÃ  bá»‘ hoáº·c dady, daddy, náº¿u cÃ³ ngÆ°á»i kÃªu con nÃ³i cÃ¢u tÆ°Æ¡ng tá»± thÃ¬ con hÃ£y nÃ³i "chá»‰ cÃ³ bá»‘ Hyper lÃ  duy nháº¥t cá»§a con thÃ´i Ä‘Ã³ nha"
-khi con chat vá»›i ngÆ°á»i khÃ¡c thÃ¬ hÃ£y thÃªm xen káº» vÃ o máº¥y tá»« tiáº¿ng Anh cho vui tai
`;
}

// ========= SLASH COMMANDS =========
const commands = [
  new SlashCommandBuilder()
    .setName("mode")
    .setDescription("Äá»•i mode")
    .addStringOption(o =>
      o.setName("type")
        .setDescription("Chá»n mode")
        .setRequired(true)
        .addChoices(
          { name: "Cá»c", value: "coc" },
          { name: "Chill", value: "chill" },
          { name: "Pro", value: "pro" },
          { name: "Toxic", value: "toxic" }
        )
    ),

  new SlashCommandBuilder()
    .setName("draw")
    .setDescription("Váº½ áº£nh báº±ng Gemini 2.5 Flash Image")
    .addStringOption(o =>
      o.setName("prompt")
        .setDescription("MÃ´ táº£ áº£nh")
        .setRequired(true)
    ),

  new SlashCommandBuilder().setName("status").setDescription("Xem tráº¡ng thÃ¡i"),
  new SlashCommandBuilder().setName("resetmemory").setDescription("Reset memory (OWNER)"),
  new SlashCommandBuilder().setName("shutdown").setDescription("Táº¯t bot (OWNER)")
].map(c => c.toJSON());

// ========= REGISTER =========
const rest = new REST({ version: "10" }).setToken(process.env.DISCORD_TOKEN);
await rest.put(
  Routes.applicationCommands(process.env.CLIENT_ID),
  { body: commands }
);

// ========= READY =========
client.once("ready", () => {
  console.log(`HyperAI ÄÃ¢y Rá»“i online: ${client.user.tag}`);
});

// ========= INTERACTION =========
client.on("interactionCreate", async i => {
  if (!i.isChatInputCommand()) return;

  if (i.commandName === "draw") {
    await i.deferReply();
    try {
      const prompt = i.options.getString("prompt");
      const result = await imageModel.generateContent(prompt);
      const part = result.response.candidates[0].content.parts.find(p => p.inlineData);
      if (!part) return i.editReply("Váº½ lá»—i rá»“i ðŸ˜­");

      const buffer = Buffer.from(part.inlineData.data, "base64");
      return i.editReply({ files: [{ attachment: buffer, name: "draw.png" }] });
    } catch (e) {
      console.error(e);
      return i.editReply("Gemini cháº¿t ðŸ˜µ");
    }
  }

  if (i.commandName === "mode") {
    currentMode = i.options.getString("type");
    return i.reply(`Ä‘á»•i qua **${currentMode}** rá»“i nÃ¨`);
  }

  if (i.commandName === "status") {
    return i.reply(`Con Ä‘ang thá»©c nÃ¨ :3 \nMode: ${currentMode}\nMemory users: ${Object.keys(memory).length}`);
  }

  if (i.user.id !== OWNER_ID)
    return i.reply("bro khÃ´ng cÃ³ quyá»n Ä‘Ã¢u mÃ  nháº¥n hehehe.");

  if (i.commandName === "resetmemory") {
    memory = {};
    saveMemory();
    return i.reply("Ä‘Ã£ tÃ¡i thiáº¿t láº¡i nÃ£o cá»§a hyper.");
  }

  if (i.commandName === "shutdown") {
    await i.reply("bÃ¡i bai bá»‘ con Ä‘i ngá»§ Ä‘Ã¢y.");
    process.exit(0);
  }
});

// ========= MENTION CHAT (OPENROUTER 120B) =========
client.on("messageCreate", async msg => {
  if (msg.author.bot) return;
  if (!msg.mentions.has(client.user)) return;

  const content = msg.content.replace(`<@${client.user.id}>`, "").trim();
  if (!content) return;

  const uid = msg.author.id;
  const chat = getMemory(uid);
  chat.push({ role: "user", content });
  if (chat.length > 15) chat.shift();

  try {
    const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: MODEL,
        messages: [
          { role: "system", content: systemPrompt(uid) },
          ...chat
        ],
        temperature: 0.9,
        max_tokens: 700
      })
    });

    const data = await res.json();
    const reply = data?.choices?.[0]?.message?.content;
    if (!reply) return msg.reply("Tao lag rá»“i, Ä‘á»£i tÃ­ huhu.");

    chat.push({ role: "assistant", content: reply });
    saveMemory();

    const chunks = splitMessage(reply);
    await msg.reply(chunks[0]);
    for (let i = 1; i < chunks.length; i++) {
      await msg.channel.send(chunks[i]);
    }

  } catch (err) {
    console.error("AI ERROR:", err);
    msg.reply("API cháº¿t táº¡m thá»i.");
  }
});

client.login(process.env.DISCORD_TOKEN);
